\documentclass[french]{article}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage[french]{babel}
\usepackage{amsmath}
\usepackage{mathtools}
\usepackage{color}
\usepackage[svgnames,dvipsnames]{xcolor} 
\usepackage{soul}
\usepackage{amssymb}
\usepackage{enumitem}
\usepackage{multicol}
\usepackage[left=2cm,right=2cm,top=2cm,bottom=2cm]{geometry}
\newcommand{\mathcolorbox}[2]{\colorbox{#1}{$\displaystyle #2$}}
\usepackage{pifont}
\usepackage{pst-all}
\usepackage{pstricks}
\usepackage{delarray}
\usepackage{setspace}
\usepackage{graphicx}
\usepackage{hyperref}
\usepackage{nicematrix}
\usepackage{listings}
\usepackage{float}

\hypersetup{
	colorlinks=true,
	linkcolor=blue,
	filecolor=magenta,      
	urlcolor=cyan,
	pdfpagemode=FullScreen,
}

\usepackage{amsthm}
\newtheorem*{Rem}{Remarque}

\newenvironment{conclusion}[1]{%
	\begin{center}\normalfont\textbf{Conclusion}\end{center}
	\begin{quotation} #1 \end{quotation}
}{%
	\vspace{1cm}
}

\newcommand\pythonstyle{\lstset{
	language=Python,
	basicstyle=\ttm,
	morekeywords={self},              % Add keywords here
	keywordstyle=\ttb\color{deepblue},
	emph={MyClass,__init__},          % Custom highlighting
	emphstyle=\ttb\color{deepred},    % Custom highlighting style
	stringstyle=\color{deepgreen},
	frame=tb,                         % Any extra options here
	showstringspaces=false
}}

\lstdefinestyle{Cpp}{
	language=C++,
	tabsize=3,
	basicstyle=\ttfamily,
	keywordstyle=\color{blue}\ttfamily,
	stringstyle=\color{red}\ttfamily,
	commentstyle=\color{green}\ttfamily,
	morecomment=[l][\color{magenta}]{\#}
}

\lstdefinestyle{Python}{
	language=Python,
	tabsize=3,
	basicstyle=\ttfamily,
	keywordstyle=\color{blue}\ttfamily,
	stringstyle=\color{red}\ttfamily,
	commentstyle=\color{green}\ttfamily,
	morecomment=[l][\color{magenta}]{\#}
}

\lstset{style=Cpp}

\usepackage{fontawesome}

\begin{document}
	LECOURTIER Frédérique \hfill \today
	\begin{center}
		\Large\textbf{{Abstracts}}
	\end{center}
\section{Semaine 1 : 06/02/2023 - 10/02/2023}
	Pendant cette première semaine, j'ai du me familiariser avec le code "phifem" écrit par Vincent Vigon et les codes de génération des données fournit par Killian. L'idée étant de comprendre comment générer les données avec FEniCS pour ensuite les faire apprendre par un FNO. Après la réunion du 07/02, il semblerait que le sujet du stage porte sur l'entrainement d'un FNO puis la correction/certification des prédictions.
\section{Semaine 2 : 13/02/2023 - 17/02/2023}
	(Les résultats en semaine 1 ont été obtenus en début de semaine.)
	
	Après la semaine dernière, on s'est dit qu'une bonne idée serait de prendre une solution manufacturée (analytique) afin de pouvoir comparer les erreurs avec FEM classique, PhiFEM, le FNO et le FNO+correction. On a choisi de prendre $u$ comme une gaussienne et ainsi le f associé. Attention, il a fallut normaliser les F pour le FNO. On a également eut l'idée d'utiliser une solution sur-raffinée (à la place d'une solution exacte) mais ça n'a pas encore été testé.
\section{Semaine 3 : 20/02/2023 - 24/02/2023}
	Pour cette semaine, on considère une nouvelle solution analytique (solution trigonométrique : $\sin*\cos$). Avec cette nouvelle solution, on va pouvoir prendre g différent de $u_{ex}$ sur $\Omega$ comme souhaité pendant la semaine précédente. 
	
	A défaut de pouvoir faire tourner les entrainements (car plus d'units dispo sur colab) et en attente d'une solution avec v100, on va s'intéresser uniquement au problème de correction où on prendra comme $\bar{\phi}$ notre $u_{ex}$ ($-g$ si non homogène). En lui donnant comme nouvelle levelset notre solution exacte, $C$ doit être très proche de 1 (à l'erreur machine).  
\section{Semaine 4 : 27/02/2023 - 03/03/2023}
	On cherche à comprendre les problèmes d'interpolation de phi dans le cadre de la correction sur la solution exacte du problème de poisson avec condition de dirichlet homogène. Après la réunion du 28/02 avec Emmanuel et Vanessa, les points suivants sont à traiter :
	\begin{enumerate}[label=\textbullet]
		\item tester avec solution analytique + perturbation !
		\item enlever les termes de stabilisation afin de voir si le problème est dans la dérivée seconde de phi
		\item visualiser le $\phi$ et le $\phi'$ EF et le comparer au $\phi$ et $\phi'$ analytique
		\item comprendre le problème du extrapolate
	\end{enumerate}
	Après la réception d'un ordinateur, on a passé la moitié de la semaine à essayer d'installer ce dont on avait besoin. En fin de semaine, les installations ont enfin été faite et je peux maintenant générer des données et entraîner le modèle sur ce nouveau PC.
\section{Semaine 5 : 06/03/2023 - 10/03/2023}
	Pendant cette semaine, on a globalement cherché à comprendre les problèmes liés à l'interpolation de $\phi$. On s'est donc concentré sur la précision de la correction lorsque l'on prend la solution analytique en entrée. On a testé avec deux solutions analytiques : la solution trigonométrique considérées précédemment et une solution polynomiale. La partie où l'on va utilisé le FNO sera considéré dans un second temps.
\section{Semaine 6 : 13/03/2023 - 17/03/2023}
	Après les tests de la semaine dernière sur la partie de correction/certification du modèle où l'on prend la solution analytique comme nouvelle level-set, il semblerait que la méthode avec les meilleurs résultats soit celle où l'on utilise la méthode extrapolate de FEniCS. C'est pourquoi, cette semaine on s'est intéressé en détail au code source de cette fonction FEniCS (\href{https://fenics.readthedocs.io/projects/dolfin/en/2017.2.0/apis/api_adaptivity.html#extrapolation}{Extrapolation}). Étant donné que je n'étais pas présente mardi, mercredi après-midi et jeudi car j'étais malade, c'est tout ce qui a été fait cette semaine. De plus, une grosse partie de la méthode reste encore floue : la construction de la matrice A (pour la résolution du système linéaire dans compute\_coefficients).
\section{Semaine 7 : 20/03/2023 - 24/03/2023}
	Lundi : Après discussion avec Michel des résultats obtenus les semaines précédentes, on a décidé de se concentrer sur la comparaison des erreurs PhiFEM, FNO et avec la correction (avec la méthode extrapolate de FEniCS). On a également parlé d'entrainer le modèle avec des données plus fines (nb\_vert=128). Sur ma machine, ça n'a pas été possible (OOM : Out Of Memory). Je me suis donc connectée à Titan sur lequel l'entrainement a également crashé (Noyau mort). Je pense que le problème vient de l'installation de tensorflow (car j'ai cloné sur Titan l'environnement conda phifem) : il faudrait tester d'installer htop pour voir si la RAM est pleine. C'est un problème qui est mis de côté pour l'instant.
	
	Mardi : Après discussion avec Michel et Emmanuel, Emmanuel a proposé de regarder les facteurs de division d'erreur sur la solution analytique pour différents $\mathbb{P}^k$. (Ensuite, on a une réunion d'équipe sur les FNO) Puis, une fois ces résultats obtenus, Michel a proposé de vérifier les pentes de convergence au niveau de l'interpolation de la level-set et sur la correction. Il a également proposé une nouvelle idée pour faire en sorte que la correction soit moins couteuse que PhiFEM classique : On entraine le réseau en $32\times 32 \; \mathbb{P}^2$ puis on applique la correction sur du $\mathbb{P}^1$ puis on compare les erreurs (PhiFEM, FNO et FNO+Corr).
	
	Pour le reste de la semaine, on s'est alors concentré sur cette nouvelle idée pour le FNO. La première complexité a été de pouvoir faire le passage d'une solution $\mathbb{P}^2$ de Numpy à FEniCS et de FEniCS à Numpy. Au vue des résultats obtenus sur la solution analytique trigonométrique, on pense qu'il est possible que les données soient "trop simple" (ne varie pas assez) pour que la correction ait un intérêt. En effet, il semblerait qu'un entrainement de seulement 500 époques nous donnent déjà de très bons résultats avec le FNO. La correction a alors du mal à corriger la solution obtenue par le FNO car elle est déjà très bonne. Pour justifier cette hypothèse, on choisit de changer le problème considéré : on repasse à Poisson avec condition de Dirichlet homogène où on prend $f$ gaussienne. Comme l'on a pas de solution analytique pour ce problème, on considérera une solution sur-raffinée comme solution de référence. 
\section{Semaine 8 : 27/03/2023 - 31/03/2023}
	L'idée principale de la semaine et de tester de rehausser la solution. Deux méthodes ont été proposées : rehausser par une constante $m$ (proposée par Emmanuel) ou rehausser par la level-set initial $\phi$ (proposée par Michel).
	
	J'ai également essayé de faire des boxplots pour comparer FEM standard, $\phi$-FEM, FNO et FNO+Corr (pour différents nombres d'époques).
\section{Semaine 9 : 03/04/2023 - 07/04/2023}
	Après les résultats obtenus avec le FNO, on va essayer de comparer les temps d'exécution et les erreurs obtenus pour FEM, Phi-FEM, le FNO et le FNO+corr à différentes époques.
	
	Après discussion avec Emmanuel, on va considérer une level-set du type $\tilde{\phi}=u_{ex}+\epsilon*P$. On va tester le rehaussement avec FEM puis avec PhiFEM pour différents $m$ sur cette solution perturbée.
	
	(Vendredi est férié)
\section{Semaine 10 : 10/04/2023 - 14/04/2023}
	(Lundi est férié)
	
	Après discussion avec Michel et Emmanuel mardi matin, on a discuté de quelques points qu'il faudrait traité suite aux résultats obtenus avec PhiFEM :
	\begin{enumerate}[label=\textbullet]
		\item On garde la fonction $\phi_c(x,y)=||x-0.5||_\infty-0.5$ pour construire les ensembles utilisés par PhiFEM. On utilise la levelset suivante pour PhiFEM : $\phi(x,y)=x(1-x)y(1-y)$.
		\item On effectue les courbes de convergence de PhiFEM sur le carré et sur le cercle pour ce problème. On étudiera également les erreurs d'interpolation.
		\item On cherchera ensuite à comparer les résultats FEM et PhiFEM. En effet, la semaine dernière on a considéré le même problème pour les deux méthodes mais les résultats obtenus sont très différents.
		\item Pour finir, Michel a proposé une analyse pour la sortie du FNO : la décomposition en série de Fourier de la solution (ce qui nous permettrait de déterminer dans lequel des cas on se trouve, parmis ceux observés sur la solution analytique et ainsi d'avoir une idée de la forme de la perturbation en sortie du FNO). Problème : Je ne comprends pas ce qui nous garantit que l'on peut faire cette décomposition, la sortie n'est pas forcément périodique !
	\end{enumerate}
	On a également remarqué qu'il faut penser à prendre un epsilon de tolérance pour la construction des espaces (car si la la levelset se situe exactement à l'intersection de deux cellules il peut y avoir des problèmes d'arrondis).
\section{Semaine 11 : 17/04/2023 - 21/04/2023}
	Après discussion avec Emmanuel vendredi 14/04, les points suivants vont être traités cette semaine :
	\begin{enumerate}[label=\textbullet]
		\item On cherchera dans un premier temps à comprendre pourquoi FEM n'a pas l'air de fonctionner aussi bien que PhiFEM en prenant $f=f_p$ et en faisant varier $\epsilon$.
		\item On va ensuite tester le rehaussement avec FEM et PhiFEM avec la solution exacte (sans perturbation, $\epsilon=0$).
		\item On ecrira ensuite les formulations pour le rehaussement avec PhiFEM "au propre".
		\item On testera ensuite d'appliquer les conditions limites pour PhiFEM différemment : on les impose de manière forte sur notre bord approché $\Gamma_h$.
	\end{enumerate}
	(Cette semaine, Michel est en vacance.)
\section{Semaine 12 : 24/04/2023 - 28/04/2023}
	Cette semaine, j'ai corrigé certains des problèmes obtenus la semaine dernière. Les bons résultats sont présentés en semaine 11. J'ai également rédigé un document expliquant l'intérêt du rehaussement.
\section{Semaine 13 : 01/05/2023 - 05/05/2023}
	On considère le problème de Poisson avec condition de Dirichlet homogène ou non homogène :
	\begin{equation}
		\label{pb1}
		\left\{\begin{aligned}
			&-\Delta u=f \quad &&\Omega \\
			&u=g \quad &&\Gamma
		\end{aligned}\right. \tag{$\mathcal{E}_1$}
	\end{equation}
	
	On a ainsi une EDP que l'on souhaite résoudre sur un domaine $\Omega$. On note $\Gamma$ le bord de $\Omega$, c'est-à-dire $\Gamma=\partial\Omega$. 
	
	Dans notre cas, on souhaite appliquer une correction à la sortie d'un FNO.
	On considère ici que l'on possède une solution analytique $u$ et qu'après une utilisation du FNO, on obtient une solution du type
	\begin{equation*}
		\label{phi_tild}
		\tilde{\phi}(x,y)=u_p(x,y) = u(x,y)-\epsilon P(x,y)
	\end{equation*}
	avec $P$ la perturbation (tel que $P=0$ sur $\Gamma$) et $\epsilon$ petit.
	
	Ce document a pour but de comparer deux méthodes de correction de la solution obtenue.
\section{Semaine 14 : 08/05/2023 - 12/05/2023}
	On souhaite faire fonctionner le rehaussement avec PhiFEM en utilisant la méthode duale. On commencera par faire les courbes de convergence puis on comparera pour différent cas tests, les erreurs en norme $L^2$ des méthodes suivantes : $\Phi$-FEM par méthode directe, $\Phi$-FEM par méthode duale, Correction par multiplication sans rehaussement, Correction par multiplication avec rehaussement par méthode duale, Correction par addition.
	
	Après discussion avec Emmanuel, il semblerait que les résultats obtenus pour $\tilde{\phi}$ de degré 2 ne soient pas aberrant. On va alors continuer les tests sur le FNO en lui appliquant les mêmes méthodes de correction que celles testées sur la solution analytique.
	
	Après relecture du document sur le rehaussement par Michel, il m'a demandé de faire la théorie sur l'erreur d'interpolation mis dans le document pour le rehaussement (inégalité 7 qui m'avait été dite par Emmanuel). Jeudi, on a alors discuté de ça avec Michel et vendredi j'ai alors relu ce que Michel avait fait pour essayer de bien comprendre.
\section{Semaine 15 : 15/05/2023 - 19/05/2023}
	(Killian est en vacances pour les deux prochaines semaines)
	
	Au tout début de la semaine, j'ai fait un petit test où je comparais la méthode duale pour le rehaussement en prenant comme fonction test $v$ ou $\tilde{\phi}v$. On s'est rendu compte que cela nous donnait les mêmes résultats.
	
	Comme Emmanuel était de retour cette semaine, on a fait une réunion mardi avec Michel. Après avoir montré mes résultats sur le FNO, on a cherché des solutions afin de comprendre pourquoi ces résultats sont très différents des résultats obtenus sur la solution analytique. Dans un premier temps, ils ont proposés de tester d'implémenter un réseau multiperceptron qui nous permet d'obtenir une solution en tout point de notre domaine et donc de pouvoir tester la correction avec $\tilde{\phi}$ de de plus haut degré (10 par exemple). Par la suite, ils ont proposés une seconde idée, plus simple, qui consiste à construire une solution analytique à partir de la sortie du FNO. Ils ont proposés de tester avec Fourier, Legendre ou Hermite. J'ai alors commencé à tester avec Fourier cette semaine, les explications et résultats seront mis dans le suivi de la semaine suivante. 
	
	De plus, j'ai repris les explications de Michel sur la preuve de l'inégalité obtenu pour le rehaussement et ait rédigé un petit document qui n'est pas encore terminé. Je vais mettre ce document ici.  
\section{Semaine 16 : 22/05/2023 - 26/05/2023}
	On a entraîné un FNO avec des solutions $\mathbb{P}^2$ où nb\_vert=32. Une fois le réseau entraîné, on a cherché à appliquer divers types de correction où les résultats obtenus ne semblaient pas correspondre avec ceux obtenus sur la solution analytique. C'est pourquoi, on cherche ici à récupérer la sortie du FNO pour ensuite construire une solution analytique en utilisant les polynômes de Legendre. Finalement, on testera à nouveau les différents types de correction sur une solution $\mathbb{P}^{10}$. La première étape consistait alors à tester en 1D puis en 2D. J'ai testé dans un premier temps sur une solution analytique avec des séries/transformées de Fourier. N'ayant pas aboutit, je suis passé aux polynômes de Legendre. 
\section{Semaine 17 : 29/05/2023 - 02/06/2023}
	Cette semaine était assez courte. En effet, lundi était férié et le jeudi et le vendredi, il y a eut le déménagement.
	Globalement, cette semaine j'ai relancé mes résultats pour Legendre (avec les coefficients calculés sous formes matriciels). J'ai testé pour différents $P$ et ait considéré 3 types d'erreurs.
\section{Semaine 18 : 05/06/2023 - 09/06/2023}
	Lundi j'ai commencé à regarder comment appliquer la correction en $\mathbb{P}^{10}$ à partir de l'expression analytique obtenu par série de polynômes de Legendre. En fin de joournée, Emmanuel est passé et m'a expliqué une meilleure méthode pour calculer les coefficients des séries. 
	Dans la journée de mardi, j'ai pris le temps de trier les fichiers et mettre au propre tout le code. J'ai séparé les fonctions qui été toutes dans un même jupyter en différents fichiers pythons. J'ai également créé un fichyier de configuration "config.json" qui regroupe une partie des paramètres.
	Pour le reste de la semaine, j'ai implémenté et tester la nouvelle méthode pour calculer les coefficients de Legendre. J'ai commencé sur solution analytique 2D avec et sans changement de variables puis directement sur le FNO (sur $w$). Pour le FNO, j'ai considéré les mêmes erreurs que la semaine précédente en comparant $w$ et en comparant $u=\phi w$. On compare également errors\_legendre et errors\_FNO.
	En toute fin de semaine, j'ai également continué les tests sur la correction.
\section{Semaine 19 : 12/06/2023 - 16/06/2023}
	\noindent
	\begin{enumerate}[label=\textbullet]
		\item Cette semaine, on a commencé par essayer de comprendre pourquoi le kernel se bloquait. On a tenté de résoudre un problème de correction sur une solution analytique avec nb\_vert=300 et en degré 10 et il n'y a pas eut de soucis. C'est pourquoi, je ne comprends pas pourquoi on a ce problème !
		\item Comme on ne peut pas faire du haut degré avec Legendre, j'ai testé avec des plus petits degrés. J'ai remarqué que la projection de phi\_tild sur notre espace de fonction V\_ex pour calculer la norme L2 d'erreur prend beaucoup de temps. Avec un degré 5, on est sur environ 15s (que l'on doit multiplier par nb\_data=100 et nb\_epochs=8). Par la suite, j'ai eut un autre problème avec la correction par multiplication. En prenant P=4 polynômes de Legendre, j'obtiens exactement les mêmes erreurs pour $\tilde{\phi}$ de degré 3 ou 5. En prenant P=6 et un degré 5, mes erreurs sont moins bonnes qu'avec P=4.
		\item J'ai alors testé la convergence de la décomposition en série de Polynômes de Legendre, tout d'abord avec la méthode des trapèzes pour différents nombres de points $N$. Puis avec une méthode de quadrature de scipy (\href{https://docs.scipy.org/doc/scipy/reference/generated/scipy.integrate.quad.html#scipy.integrate.quad}{scipy.integrate.quad}) qui prend une expression analytique de notre fonction en paramètre (et pas un ensemble de valeurs à des points connus). Il semblerait alors qu'avec la méthode de scipy, on est bien la convergence attendue.
		\item J'ai également corrigé la preuve sur l'inégalité pour le rehaussement avec FEM et ait commencé à générer une documentation sphinx du code.
	\end{enumerate}
\section{Semaine 20 : 19/06/2023 - 23/06/2023}
	Cette semaine on s'est concentré sur l'implémentation d'un réseau multi-perceptron. On a commencé par implémenter un modèle capable d'approcher directement la solution $u$ à partir d'une loss $mae(y\_true-y\_pred)$ (où mae = mean absolute error). Puis on a tenté d'approcher la solution $w$ à partir de la loss $mae(y\_true-\phi y\_pred)$. Le second modèle fut plus compliqué car on a due créer une boucle d'entraînement personnalisée. L'idée étant que ces 2 modèles soient capables de prédire une solution seulement à partir d'un couple de point $(x,y)$. On considère alors $y\_true$ comme étant une solution analytique associée à une force $f$. On testera de faire varier différents paramètres afin de tester plusieurs configurations des modèles. On souhaitera ensuite comparer quels paramétrisation est la meilleure. Pour cela on comparer les loss calculées pendant l'entraînement en fonction des époques ainsi que la norme $L^2$ calculée sur un échantillon test.
	
	On souhaitera dans un second temps appliqué une correction à la sortie du réseau en $\mathbb{P}^{10}$. 
	
	Après avoir discuté avec Emmanuel vendredi matin, il semblerait que le problème au niveau de la correction puisse venir des dérivées premières et secondes de la prédiction du modèles. C'est pourquoi il a conseillé de les afficher pour voir si le problème vient de là.
	
	On a aussi commencé à préparer le rapport de stage : page de garde + début de plan + lecture sur le FNO. Il faudra par la suite commencer la rédaction. A noter que j'ai demandé à Ouiza et je n'aurais pas la possibilité de venir en août, je n'ai donc pas réellement d'autres choix que de commencer dès maintenant.
\section{Semaine 21 : 26/06/2023 - 30/06/2023}
	Cette semaine, j'ai enfin compris comment faire les dérivées. En fait, Emmanuel a expliqué que le modèle est en fait une fonction et donc qu'il peut être dérivée, ainsi on connaît les dérivées de $\phi(x,y)w_\theta(x,y)$. 
	L'idée est donc de calculer les dérivées avant le passage en P10 directement avec Tensorflow puis en P10 avec FEniCS.
	
	On a également voulu tester si le problème venait de PhiFEM donc j'ai du tester la correction avec FEM.
	
	Pour finir, j'ai commencé à tester l'implémentation de la loss H1 (avec directement la dérivée par tensorflow), ça tourne mais les loss ne diminue pas.
	
	En fin de semaine, j'ai commencé à rédiger la partie sur les FNO dans le rapport. Il a également été question d'inscription à l'ED (non aboutit, en attente des résultats), j'ai donc dû faire des modifications à mon CV.
\section{Semaine 22-23 : 03/07/2023 - 14/07/2023}
	Je regroupe ici 2 semaines car durant ces 2 dernières semaines, j'ai passé beaucoup de temps sur le rapport dont je n'ai pas encore la date de rendu. Notamment sur la mise en place de la conversion (en python) du rapport latex en un rapport antora et sur la ci permettant de mettre en ligne ce rapport antora à chaque push.
	  
	Après discussion avec Emmanuel, il aimerait que je refasse les mêmes tests sur un carré que ceux effectués sur le cercle. J'ai également essayer de continuer à entraîner avec une loss H1, cette fois sur le carré mais ça ne fonctionne pas. Ces résultats sont obtenus sur les 2 semaines.
\end{document}