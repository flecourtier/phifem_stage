\section{Fourier Neural Operator (FNO)} \label{FNO}
\graphicspath{{images/fourier}}

\modif{Est-ce que je rajouter réseau multi-perceptron et PINNs ? Si oui section "Neural Networks" puis sous-sections FNO,MultiPerceptron,PINNs}

We will now introduce Fourier Neural Operators (FNO). For more information, please refer to the following article \cite{li_fourier_2021}. \modif{+ add article Killian}

In image treatment, we call image tensors of size $ni\times nj\times nk$, where $ni\times nj$ corresponds to the image resolution and $nk$ corresponds to its number of channels. For example, an RGB (Red Green Blue) image has $nk=3$ channels. 
We choose here to present the FNO as an operator acting on discrete images. Reference articles present it in its continuous aspect, which is an interesting point of view. Indeed, it is thanks to this property that it can be trained/evaluated with images of different resolutions.

The FNO methodology creates a relationship between two spaces from a finite collection of observed input-output pairs. \modif{Est-ce que je gardes cette phrase ?}

\modif{A rajouter : implémentation effectuée/fournie par Vincent Vigon + on ne trouvera pas ici de test de variation des paramètres (modes, width...)}

\subsection{Architecture of the FNO}

The following figure (Figure \ref{FNO_schema}) describes the FNO architecture in detail:

\begin{figure}[H]
	\includegraphics[width=\linewidth]{"fno_schema.png"}
	\captionof{figure}{Architecture of the FNO.}
	\label{FNO_schema}
\end{figure}

The architecture of the FNO is as follows:

\begin{equation*}
	G_\theta = Q \circ \mathcal{H}_\theta^L \circ \dots \circ \mathcal{H}_\theta^1 \circ P
\end{equation*}

\newpage

We'll now describe the composition of the Figure \ref{FNO_schema} in a little more detail :
\begin{enumerate}[label=\textbullet]
	\item We start with input X of shape (batch\_size, height, width, nb\_channels) with batch\_size the number of images to be processed at the same time, height and width the dimensions of the images and nb\_channels the number of channels. Simplify by (bs,ni,nj,nk).
	\item We perform a $P$ transformation in order to move to a space with more channels. This step enables the network to build a sufficiently rich representation of the data.  For example, a Dense layer (also known as fully-connected) can be used. 	
	\item We then apply $L$ Fourier layers, noted $\mathcal{H}_\theta^l,\; l=1,\dots,L$, whose specifications will be detailed in Section \ref{FNO.fourierlayer}.
	\item We then return to the target dimension by performing a $Q$ transformation. In our case, the number of output channels is 1.
	\item We then obtain the output of the $Y$ model of shape (bs,ni,nj,1). 
\end{enumerate}

\subsection{Fourier Layer structure} \label{FNO.fourierlayer}

Each Fourier layer is divided into two sublayers:

\begin{equation*}
	\tilde{Y}=\mathcal{H}_\theta^l(\tilde{X})=\sigma\left(\mathcal{C}_\theta^l(\tilde{X})+\mathcal{B}_\theta^l(\tilde{X})\right)
\end{equation*}

where
\begin{enumerate}[label=\textbullet]
	\item $\tilde{X}$ corresponds to the input of the current layer and $\tilde{Y}$ to the output.
	\item $\sigma$ is an activation function. For $l=1,\dots,L-1$, we'll take the activation function ReLU (Rectified Linear Unit) and for $l=L$ we'll take the activation function GELU (Gaussian Error Linear Units).
	\begin{figure}[H]
		\centering
		\includegraphics[width=0.3\linewidth]{"activation_functions.png"}
		\captionof{figure}{Activation functions used.}
	\end{figure}
	
	\item $\mathcal{C}_\theta^l$ is a convolution layer where convolution is performed by FFT (Fast Fourier Transform). For more details, see Section \ref{FNO.conv_sublayer}.
	\item $\mathcal{B}_\theta^l$ is the "bias-layer". For more details, see Section \ref{FNO.bias_sublayer}.
\end{enumerate}

\subsubsection{Convolution sublayer} \label{FNO.conv_sublayer}

Each $\mathcal{C}_\theta^l$ convolution layer contains a trainable kernel $\hat{W}$ and performs the transformation

\begin{equation*}
	\mathcal{C}_\theta^l(X)=\mathcal{F}^{-1}(\mathcal{F}(X)\cdot\hat{W})
\end{equation*}

where $\mathcal{F}$ corresponds to the 2D Discrete Fourier Transform (DFT) on a $ni\times nj$ resolution grid and
\begin{equation*}
	(Y\cdot\hat{W})_{ijk}=\sum_{k'}Y_{ijk'}\hat{W}_{ijk'}
\end{equation*}
In other words, this transormation is applied channel by channel.

\begin{Rem}
	An image is fundamentally a signal. Just as 1D signals show changes in amplitude (sound) over time, 2D signals show variations in intensity (light) over space. The Fourier transform allows us to move from the spatial or temporal domain into the frequency domain. In a sound signal (1D signal), low frequencies represent low-pitched sounds and high frequencies represent high-pitched sounds. In the case of an image (2D signal), low frequencies represent large homogeneous surfaces and blurred parts, while high frequencies represent contours, more generally abrupt changes in intensity and, finally, noise.
\end{Rem}

The 2D DFT is defined by :

\begin{equation*}
\mathcal{F}(X)_{ijk}=\frac{1}{ni}\frac{1}{nj}\sum_{i'=0}^{ni-1}\sum_{j'=0}^{nj-1}X_{i'j'k}e^{-2\sqrt{-1}\pi\left(\frac{ii'}{ni}+\frac{jj'}{nj}\right)}
\end{equation*}

The inverse of the 2D DFT is defined by :

\begin{equation*}
\mathcal{F}^{-1}(X)_{ijk}=\sum_{i'=0}^{ni-1}\sum_{j'=0}^{nj-1}X_{i'j'k}e^{2\sqrt{-1}\pi\left(\frac{ii'}{ni}+\frac{jj'}{nj}\right)}
\end{equation*}

We can easily show that $\mathcal{F}$ is the reciprocal function of $\mathcal{F}^{-1}$. We have 

\begin{align*}
	\mathcal{F}^{-1}(\mathcal{F}(X))_{ijk}&=\sum_{i'=0}^{ni-1}\sum_{j'=0}^{nj-1}\mathcal{F}(X)_{i'j'k}e^{2\sqrt{-1}\pi\left(\frac{ii'}{ni}+\frac{jj'}{nj}\right)} \\	
	&=\frac{1}{ni}\frac{1}{nj}\sum_{i'j'}\sum_{i''j''}X_{i''j''k}e^{-2\sqrt{-1}\pi\left(\frac{i'i''}{ni}+\frac{j'j''}{nj}\right)}e^{2\sqrt{-1}\pi\left(\frac{ii'}{ni}+\frac{jj'}{nj}\right)} \\
	&=\frac{1}{ni}\frac{1}{nj}\sum_{i''j''}X_{i''j''k}\sum_{i'j'}e^{2\sqrt{-1}\pi\frac{i'}{ni}(i-i'')}e^{2\sqrt{-1}\pi\frac{j'}{nj}(j-j'')}
\end{align*}

Let

\begin{equation*}
	S=\sum_{i'j'}e^{2\sqrt{-1}\pi\frac{i'}{ni}(i-i'')}e^{2\sqrt{-1}\pi\frac{j'}{nj}(j-j'')}
\end{equation*}

Thus
\begin{enumerate}[label=\textbullet]
	\item If $(i,j)=(i'',j'')$ : $S=\sum_{i',j'}1=ni\times nj$
	\item If $(i,j)\ne(i'',j'')$ : 
	\begin{align*}
		S&=\sum_{i'}\left(e^{\frac{2\sqrt{-1}\pi}{ni}(i-i'')}\right)^{i'}\sum_{j'}\left(e^{\frac{2\sqrt{-1}\pi}{nj}(j-j'')}\right)^{j'} \\
		&=\frac{1-\left(e^{\frac{2\sqrt{-1}\pi}{ni}(i-i'')}\right)^{ni}}{1-e^{\frac{2\sqrt{-1}\pi}{ni}(i-i'')}}\times \frac{1-\left(e^{\frac{2\sqrt{-1}\pi}{nj}(j-j'')}\right)^{nj}}{1-e^{\frac{2\sqrt{-1}\pi}{nj}(j-j'')}} \\
		&=\frac{1-e^{2\sqrt{-1}\pi(i-i'')}}{1-e^{\frac{2\sqrt{-1}\pi}{ni}(i-i'')}}\times \frac{1-e^{2\sqrt{-1}\pi(j-j'')}}{1-e^{\frac{2\sqrt{-1}\pi}{ni}(j-j'')}}=0
	\end{align*}
	as the sum of a geometric sequence.
\end{enumerate}

We deduce that
\begin{equation*}
	\mathcal{F}^{-1}(\mathcal{F}(X))_{ijk} = \frac{1}{ni}\frac{1}{nj} \times ni\times nj\times X_{ijk} = X_{ijk}
\end{equation*}

And finally $\mathcal{F}$ is the reciprocal function of $\mathcal{F}^{-1}$.

For more details about the Convolution sublayer, see Section \ref{FNO.details_conv}.

\subsubsection{Bias subLayer} \label{FNO.bias_sublayer}

The bias layer is a 2D convolution with a kernel size of 1. This means that it only performs matrix multiplication on the channels, but pixel by pixel. In other words, it mixes channels via a kernel, but does not allow interaction between pixels.

Precisly,

\begin{equation*}
	\mathcal{B}_\theta^l(X)_{ijk}=\sum_{k'}X_{ijk}W_{k'k}+B_k
\end{equation*}

\subsection{Some details on the convolution sublayer} \label{FNO.details_conv}

In this section, we will specify some details for the convolution layer.

\subsubsection{Border issues}

Let $W=\mathcal{F}^{-1}(\hat{W})$, we have :
\begin{equation*}
	\mathcal{C}_\theta^l(\tilde{X})=\mathcal{F}^{-1}\left(\mathcal{F}(X)\cdot\hat{W}\right)=\tilde{X}\star W
\end{equation*}
with
\begin{equation*}
	(\tilde{X}\star W)_{ij}=\sum_{i'j'}\tilde{X}_{i-i'[ni],j-j'[nj]}W_{i'j'}
\end{equation*}

In other words, multiplying in Fourier space is equivalent to performing a $\star$ circular convolution in real space. But these modulo operations are only natural for periodic images, which is not our case. \modif{A compléter (expliquer padding par ex)}

\subsubsection{FFT}

To speed up computations, we will use the FFT (Fast Fourier Transform). The FFT is a fast algorithm to compute the DFT. It is recursive : The transformation of a signal of size $N$ is make from the decomposition of two sub-signals of size $N/2$. The complexity of the FFT is $N\log(N)$ whereas the natural algorithm, which is a matrix multiplication, has a complexity of $N^2$.

\subsubsection{Real DFT}

In reality, we'll be using a specific implementation of FFT, called RFFT (Real Fast Fourier Transorm).In fact, for $\mathcal{F}^{-1}(A)$ to be real if $A$ is a complex-valued matrix, it is necessary that A respects the Hermitian symmetry:
\begin{equation*}
	A_{i,nj-(j+1)} = \bar{A}_{i,j}
\end{equation*}

In our case, we want $\mathcal{C}_\theta^l(X)$ to be a real image, so $\mathcal{F}(X)\cdot\hat{W}$ must verify Hermitian-symmetry.

To do this, we only need to collect half of the Discrete Fourier Coefficients (DFC) and the other half will be deduced by Hermitian symmetry. More precisely, using the specific RFFT implementation, the DFCs are stored in a matrix of size $(ni,nj//2+1)$. Multiplication can then be performed by the $\hat{W}$ kernel, and when the inverse RFFT is performed, the DFCs will be automatically symmetrized. So the Hermitian symmetry of $\mathcal{F}(X)\cdot\hat{W}$ is verified and $\mathcal{C}_\theta^l(X)$ is indeed a real image.

To simplify, let's assume nk=1. Here is a diagram describing this idea:

\begin{figure}[H]
	\centering
	\includegraphics[width=\linewidth]{"symetry_schema.png"}
	\captionof{figure}{RFFT with Hermitian-symmetry scheme.}
\end{figure}

\subsubsection{Low pass filter}

When we perform a DFT on an image, the DFCs related to high frequencies are in practice very low. This is why we can easily filter an image by ignoring these high frequencies, i.e. by truncating the high Fourier modes. In fact, eliminating the higher Fourier modes enables a kind of regularization that helps the generalization. So, in practice, it's sufficient to keep only the DFCs corresponding to low frequencies. Typically, for images of resolution $32\times 32$ to $128\times 128$, we can keep only the $20\times 20$ DFCs associated to low frequencies.

Here is a representation of this idea in 1D :

\begin{figure}[H]
	\centering
	\includegraphics[width=0.5\linewidth]{"fourier_low_pass_filter.png"}
	\captionof{figure}{Low pass filter.}
\end{figure}

\subsubsection{Global aspect of the FNO}

Classical Convolutional Neural Networks (CNN) use very small kernels (typically $3\times 3$). This operation only has a local effect, and it's the sequence of many convolutions that produces more global effects. 

In addition, CNNs often use max or mean-pooling layers, which process the image on several scales. Max-pooling (respectively mean-pooling) consists in slicing the image into small pieces of size $n\times n$, then choosing the pixel with the highest value (respectively the average of the pixels) in each of the small pieces. In most cases, $n=2$ is used, which divides the number of pixels by 4.

The FNO, on the other hand, uses a $\hat{W}$ frequency kernel and $W=\mathcal{F}^{-1}(\hat{W})$ has full support. For this reason, the effect is immediately non-local. As a result, we can use less layers and we don't need to use a pooling layer.
\subsection{Application}

\trad{Dans notre cas, on souhaite apprendre au FNO à prédire des solutions d'EDP. Plus précisément, on souhaite que le réseau soit capable de prédire la solution à partir d'un terme source $f$. 
\modif{enrichissement des données, grilles régulières}}

\night{rajouter schéma}